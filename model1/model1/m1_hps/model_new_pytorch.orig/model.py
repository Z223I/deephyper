# Autogenerated by onnx-pytorch.

import glob
import os

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
  """Model class."""

  def __init__(self):
    """Initialize the model."""
    super(Model, self).__init__()
    self.__vars = nn.ParameterDict()
    for b in glob.glob(
        os.path.join(os.path.dirname(__file__), "variables", "*.npy")):
      v = torch.from_numpy(np.load(b))
      requires_grad = v.dtype.is_floating_point or v.dtype.is_complex
      self.__vars[os.path.basename(b)[:-4]] = nn.Parameter(
          torch.from_numpy(np.load(b)), requires_grad=requires_grad)


  def forward(self, *inputs):
    # sourcery skip: inline-immediately-returned-variable
    """Step forward in the model."""
    t_input_0, = inputs
    t_dense0 = torch.matmul(t_input_0, self.__vars["t_dense_kernel_0"])
    t_dense_20 = torch.matmul(t_input_0, self.__vars["t_dense_2_kernel_0"])
    t_biased_tensor_name3 = t_dense0 + self.__vars["t_dense_bias_0"]
    t_biased_tensor_name5 = t_dense_20 + self.__vars["t_dense_2_bias_0"]
    t_activation_Relu_0 = F.relu(t_biased_tensor_name3)
    t_dense_50 = torch.matmul(t_activation_Relu_0, self.__vars["t_dense_5_kernel_0"])
    t_dense_30 = torch.matmul(t_activation_Relu_0, self.__vars["t_dense_3_kernel_0"])
    t_dense_10 = torch.matmul(t_activation_Relu_0, self.__vars["t_dense_1_kernel_0"])
    t_biased_tensor_name1 = t_dense_50 + self.__vars["t_dense_5_bias_0"]
    t_biased_tensor_name4 = t_dense_30 + self.__vars["t_dense_3_bias_0"]
    t_biased_tensor_name6 = t_dense_10 + self.__vars["t_dense_1_bias_0"]
    t_activation_1_Relu_0 = F.relu(t_biased_tensor_name6)
    t_intermediate_tensor = t_activation_1_Relu_0 + t_biased_tensor_name5
    t_add_add_1_0 = t_intermediate_tensor + t_biased_tensor_name4
    t_activation_2_Relu_0 = F.relu(t_add_add_1_0)
    t_dense_40 = torch.matmul(t_activation_2_Relu_0, self.__vars["t_dense_4_kernel_0"])
    t_biased_tensor_name2 = t_dense_40 + self.__vars["t_dense_4_bias_0"]
    t_activation_3_Tanh_0 = torch.tanh(t_biased_tensor_name2)
    t_add_1_add_0 = t_activation_3_Tanh_0 + t_biased_tensor_name1
    t_activation_4_Relu_0 = F.relu(t_add_1_add_0)
    t_dense_60 = torch.matmul(t_activation_4_Relu_0, self.__vars["t_dense_6_kernel_0"])
    t_dense_6 = t_dense_60 + self.__vars["t_dense_6_bias_0"]
    return t_dense_6


@torch.no_grad()
def test_run_model(inputs=[torch.from_numpy(np.random.randn(*[1, 1690]).astype(np.float32))]):
  """Test the model."""
  model = Model()
  model.eval()
  print(model)
  rs = model(*inputs)
  print(rs)
  return rs



if __name__ == '__main__':
    config = {
        'proportion': .80,          # A value between [0., 1.] indicating how to split data between
                                    # training set and validation set. `prop` corresponds to the
                                    # ratio of data in training set. `1.-prop` corresponds to the
                                    # amount of data in validation set.
        'print_shape': 0            # Print the data shape.
    }

    from load_data_pytorch import load_data
    (x_train, y_train), (x_valid, y_valid) = load_data(config)

    arrayOf2dList = x_valid[0:50]
    numpyArrayOf2dListFloat64 = np.array( arrayOf2dList )
    numpyArrayOf2dListFloat32 = numpyArrayOf2dListFloat64.astype(np.float32)
    torchTensorOf2dListFloat32 = torch.from_numpy( numpyArrayOf2dListFloat32 )
    inputs = [ torchTensorOf2dListFloat32 ]
    test_run_model( inputs )
