{
"name": "model_1",
"layers":
    [



{"class_name": "InputLayer",
        "config": {"batch_input_shape": [null, 1690],
        "dtype": "float32",
        "sparse": false,
        "ragged": false,
        "name": "input_0"},
    "name": "input_0",
    "inbound_nodes": []},





{"class_name": "Dense",
"config": {
"name": "dense",
"trainable": true,
"dtype": "float32",
"units": 80,
"activation": "linear",
"use_bias": true,
"kernel_initializer":

{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":

{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},
"name": "dense",
"inbound_nodes": [[["input_0", 0, 0, {}]]]},

self.dense   = nn.LayerNorm(input_shape).to(device, dtype=dtype)

#if batchSamples >= 16:
in_features = numInputs
out_features = 80
self.fc1 = nn.Linear(in_features, out_features).to(device, dtype=dtype)
self.dropout_1 = nn.Dropout2d(dropout1).to(device, dtype=dtype)




{"class_name": "Activation",
"config": {
"name": "activation",
"trainable": true,
"dtype": "float32",
"activation": "sigmoid"},

"name": "activation",
"inbound_nodes": [[["dense", 0, 0, {}]]]},

self.activation = torch.nn.Sigmoid()



{"class_name": "Dense",
"config": {
"name": "dense_1",
"trainable": true,
"dtype": "float32",
"units": 80,
"activation": "linear",
"use_bias": true,
"kernel_initializer":
{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":
{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},

"name": "dense_1",
"inbound_nodes": [[["input_0", 0, 0, {}]]]},

#if batchSamples >= 12:
in_features = out_features
out_features = 80
self.dense_1 = nn.Linear(in_features, out_features).to(device, dtype=dtype)
self.dropout_2 = nn.Dropout2d(dropout2).to(device, dtype=dtype)






{"class_name": "Add",
"config": {
"name": "add",
"trainable": true,
"dtype": "float32"},

"name": "add",
"inbound_nodes": [[["activation", 0, 0, {}], ["dense_1", 0, 0, {}]]]},

# activation, dense_1
# Add
out_features = 1
self.add = torch.nn.Sum()






{"class_name": "Activation",
"config": {
"name": "activation_1",
"trainable": true,
"dtype": "float32",
"activation": "relu"},

"name": "activation_1",
"inbound_nodes": [[["add", 0, 0, {}]]]},

# Can use ReLU(inplace=False)
out_features = 1
self.activation_1 = torch.nn.ReLU()





{"class_name": "Dense",
"config": {
"name": "dense_2",
"trainable": true,
"dtype": "float32",
"units": 96,
"activation": "linear",
"use_bias": true,
"kernel_initializer":

{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":

{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},

"name": "dense_2",
"inbound_nodes": [[["activation_1", 0, 0, {}]]]},

#if batchSamples >= 10:
in_features = out_features
out_features = 96
self.dense_2 = nn.Linear(in_features, out_features).to(device, dtype=dtype)
self.dropout_3 = nn.Dropout2d(dropout2).to(device, dtype=dtype)





{"class_name": "Activation",
"config": {
"name": "activation_2",
"trainable": true,
"dtype": "float32",
"activation": "tanh"},

"name": "activation_2",
"inbound_nodes": [[["dense_2", 0, 0, {}]]]},

out_features = 1
self.activation_2 = torch.nn.Tanh()





{"class_name": "Dense",
"config": {
"name": "dense_3",
"trainable": true,
"dtype": "float32",
"units": 96,
"activation": "linear",
"use_bias": true,
"kernel_initializer":


{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":

{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},

"name": "dense_3",
"inbound_nodes": [[["activation_1", 0, 0, {}]]]},

in_features = out_features
out_features = 96
self.dense_3 = nn.Linear(in_features, out_features).to(device, dtype=dtype)
self.dropout_4 = nn.Dropout2d(dropout3).to(device, dtype=dtype)





{"class_name": "Add",
"config": {
"name": "add_1",
"trainable": true,
"dtype": "float32"},

"name": "add_1",
"inbound_nodes": [[["activation_2", 0, 0, {}], ["dense_3", 0, 0, {}]]]},

# activation_2, dense_3
out_features = 1
self.add_1 = torch.nn.Sum()





{"class_name": "Activation",
"config": {
"name": "activation_3",
"trainable": true,
"dtype": "float32",
"activation": "relu"},

"name": "activation_3",
"inbound_nodes": [[["add_1", 0, 0, {}]]]},

# Can use ReLU(inplace=False)
out_features = 1
self.activation_3 = torch.nn.ReLU()





{"class_name": "Dense",
"config": {
"name": "dense_4",
"trainable": true,
"dtype": "float32",
"units": 80,
"activation": "linear",
"use_bias": true,
"kernel_initializer":

{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":

{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},

"name": "dense_4",
"inbound_nodes": [[["activation_3", 0, 0, {}]]]},

in_features = out_features
out_features = 80
self.dense_4 = nn.Linear(in_features, out_features).to(device, dtype=dtype)
self.dropout_5 = nn.Dropout2d(dropout4).to(device, dtype=dtype)





{"class_name": "Activation",
"config": {
"name": "activation_4",
"trainable": true,
"dtype": "float32",
"activation": "sigmoid"},

"name": "activation_4",
"inbound_nodes": [[["dense_4", 0, 0, {}]]]},

out_features = 1
self.activation = torch.nn.Sigmoid()





{"class_name": "Dense",
"config": {
"name": "dense_5",
"trainable": true,
"dtype": "float32",
"units": 80,
"activation": "linear",
"use_bias": true,
"kernel_initializer":

{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":

{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},

"name": "dense_5",
"inbound_nodes": [[["input_0", 0, 0, {}]]]},

in_features = out_features
out_features = 80
self.dense_5 = nn.Linear(in_features, out_features).to(device, dtype=dtype)
self.dropout_6 = nn.Dropout2d(dropout4).to(device, dtype=dtype)





{"class_name": "Dense",
"config": {
"name": "dense_6",
"trainable": true,
"dtype": "float32",
"units": 80,
"activation": "linear",
"use_bias": true,
"kernel_initializer":

{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":

{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},

"name": "dense_6",
"inbound_nodes": [[["activation_3", 0, 0, {}]]]},

in_features = out_features
out_features = 80
self.dense_6 = nn.Linear(in_features, out_features).to(device, dtype=dtype)
self.dropout_7 = nn.Dropout2d(dropout4).to(device, dtype=dtype)







{"class_name": "Add",
"config": {
"name": "add_2",
"trainable": true,
"dtype": "float32"},

"name": "add_2",
"inbound_nodes": [[["activation_4", 0, 0, {}], ["dense_5", 0, 0, {}], ["activation_1", 0, 0, {}], ["dense_6", 0, 0, {}]]]},

#"activation_4, dense_5, activation_1, dense_6
out_features = 1
self.add_2 = torch.nn.Sum()





{"class_name": "Activation",
"config": {
"name": "activation_5",
"trainable": true,
"dtype": "float32",
"activation": "relu"},

"name": "activation_5",
"inbound_nodes": [[["add_2", 0, 0, {}]]]},

# Can use ReLU(inplace=False)
out_features = 1
self.activation_5 = torch.nn.ReLU()





{"class_name": "Dense",
"config": {
"name": "dense_7",
"trainable": true,
"dtype": "float32",
"units": 1,
"activation": "linear",
"use_bias": true,
"kernel_initializer":


{"class_name": "GlorotUniform",
"config": {"seed": null}},
"bias_initializer":

{"class_name": "Zeros",
"config": {}},
"kernel_regularizer": null,
"bias_regularizer": null,
"activity_regularizer": null,
"kernel_constraint": null,
"bias_constraint": null},

"name": "dense_7",
"inbound_nodes": [[["activation_5", 0, 0, {}]]]}],

in_features = out_features
out_features = 2
self.dense_7 = nn.Linear(in_features, out_features).to(device, dtype=dtype)





"input_layers": [["input_0", 0, 0]],
"output_layers": [["dense_7", 0, 0]]}